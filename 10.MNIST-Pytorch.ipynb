{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ef41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt;\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3;\n",
    "batch_size_train = 64;\n",
    "batch_size_test = 1000;\n",
    "lr = 0.01;momentum = 0.5\n",
    "random_seed= 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e951204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/eaglesmac/opt/anaconda3/envs/learnPy/lib/python3.8/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1616554845587/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed);#设置随机数种子\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('./data/',train=True,download=True,\n",
    "                                                                      transform=torchvision.transforms.Compose([\n",
    "                                                                          torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.1307,),(0.3081,))#二值化\n",
    "                                                                    ])),batch_size=batch_size_train,shuffle=True);\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('./data/',train=False,download=True,\n",
    "                                                                     transform=torchvision.transforms.Compose([\n",
    "                                                                         torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                                    ])),batch_size=batch_size_test,shuffle = True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be0e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "###dataset test###\n",
    "examples=enumerate(test_loader);\n",
    "batch_idx,(examples_data,examples_targets)=next(examples);\n",
    "print(examples_data.shape);#---->torch.Size([1000, 1, 28, 28])说明这里是1000*1*28*28的矩阵(黑白双通道图像)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "996db5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1);\n",
    "    plt.tight_layout();\n",
    "    plt.imshow(examples_data[i][0],cmap='gray',interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15eec375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建模型\n",
    "class NetWrok(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Sequential(nn.Conv2d(1,64,kernel_size=3,padding=1),#h=w=(28*2*1-3)/1+1=28\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64,128,kernel_size=3,padding=1),#h=w=(28*2*1-3)/1+1=28\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2,2))#h=w=28/2=14\n",
    "        self.fc = torch.nn.Sequential(nn.Linear(14*14*128,1024),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(),#二维空间中的元素有50%的概率被置为0, 防止模型的过拟合\n",
    "                                      nn.Linear(1024,10))\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 14 * 14 * 128)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab4702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetWrok(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout2d(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###训练\n",
    "model= NetWrok()\n",
    "model.to(device)\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "print(model)#查看模型结构\n",
    "#用于保存模型\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(EPOCH + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9116aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    model.train()\n",
    "    for batch_idx,(data,target)in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data=data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss =F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #每10个iter保存一次\n",
    "        if batch_idx%10==0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx * 64) + ((epoch - 1) * len(train_loader.dataset)))\n",
    "            torch.save(model.state_dict(),'./run/MNIST/train/model.pth')\n",
    "            torch.save(optimizer.state_dict(),'./run/MNIST/train/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a55ff300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target=target.to(device)\n",
    "            output=model(data)\n",
    "            test_loss += F.nll_loss(output,target,size_average=False).item()\n",
    "            pred = output.data.max(1,keepdim=True)[1]\n",
    "            correct+=pred.eq(target.data.view_as(pred)).sum()\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_losses.append(test_loss)\n",
    "            print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                100. * correct / len(test_loader.dataset)))\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2168c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-168ec425bf87>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.294791\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.829239\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.306387\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.747914\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.596025\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.550432\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.549299\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.541047\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.664705\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.571712\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.522464\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.494310\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.342021\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.261658\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.473837\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.379444\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.509078\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.253452\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.353471\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.308322\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.362434\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.258983\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.392028\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.366150\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.448478\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.439355\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.345100\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.232678\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.182868\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.619748\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.190294\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.250574\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.228885\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.354306\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.251152\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.078741\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.179750\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.185419\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.315911\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.111468\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.197008\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.253692\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.392282\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.241773\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.166416\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.233066\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.357619\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.115789\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.236955\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.165733\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.224402\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.194388\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.264591\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.159243\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.189621\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.145959\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.277118\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.349901\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.116989\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.195780\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.353616\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.238494\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.133783\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.258374\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.244430\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.094667\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.290290\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.372196\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.361995\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.161720\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.239149\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.220034\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.272322\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.121233\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.105430\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.253706\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.093394\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.256595\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.147792\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.116608\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.095865\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.180877\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.135633\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.159198\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.097304\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.079268\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.119357\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.206451\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.169826\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.252891\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.117487\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.270490\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.071326\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.083387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eaglesmac/opt/anaconda3/envs/learnPy/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0109, Accuracy: 969/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 1934/10000 (19%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 2899/10000 (29%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0136, Accuracy: 3861/10000 (39%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0145, Accuracy: 4814/10000 (48%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 5785/10000 (58%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0127, Accuracy: 6745/10000 (67%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 7716/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 8687/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0121, Accuracy: 9651/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.112175\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.204902\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.132156\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.060545\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.070139\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.039700\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.109652\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.129621\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.345903\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.119769\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.237266\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.130051\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.077867\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.263129\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.035868\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.084914\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.053347\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.101507\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.220966\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.123218\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.143174\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.241318\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.189869\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.120953\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.053547\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.094827\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.066177\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.063571\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.047472\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.117776\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.097206\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.157739\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.116195\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.183903\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.323066\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.087660\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.133308\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.209392\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.205198\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.131107\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.173191\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.092565\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.068787\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.028962\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.131867\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.404133\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.056266\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.159662\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.029055\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.072365\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.087990\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.196335\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.079443\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.088064\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.054842\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.080118\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.064146\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.068392\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.199844\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.133221\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.046294\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.068021\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.050994\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.011742\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.050601\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.100608\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.086082\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.165744\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.071563\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.127096\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.089820\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.043618\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.104718\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.029095\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.067950\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097503\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.102058\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.092739\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.068243\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.104187\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.033712\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.127997\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.068040\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.098884\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.056164\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.167096\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.211114\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.117760\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.022730\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.078299\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.101112\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.334465\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.111902\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.161376\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 981/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055, Accuracy: 1963/10000 (20%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058, Accuracy: 2946/10000 (29%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053, Accuracy: 3930/10000 (39%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074, Accuracy: 4906/10000 (49%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 5883/10000 (59%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0063, Accuracy: 6864/10000 (69%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0071, Accuracy: 7842/10000 (78%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070, Accuracy: 8819/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0071, Accuracy: 9799/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.106915\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.111267\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.018891\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.100636\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.048984\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.049710\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.225873\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.063774\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.160816\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.147547\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.027660\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.079921\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.078460\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.148775\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.071761\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.084252\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.044451\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.175651\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.045214\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.050185\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.063562\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.030504\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.145600\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.038292\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.021651\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.034207\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.148817\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.120968\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.041041\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.027098\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.020192\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.022036\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.051083\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.017383\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.131013\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.047476\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.102982\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.044961\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.056956\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.120347\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.153651\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.079261\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.046689\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.094509\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.093849\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.131251\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.014321\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.120462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.039876\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.018424\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.008931\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.022772\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.043839\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.140017\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.017011\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.034202\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.038131\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.046281\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.037599\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.026415\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.039771\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.025312\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.050244\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.031174\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.087724\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.090580\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.081026\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.149224\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.077075\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.049447\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.098775\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.056069\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.074111\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.078451\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.024013\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.113631\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.019464\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.044411\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.072091\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.037186\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.106811\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.112940\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.082171\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.033033\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.062988\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.109928\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.060652\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.029874\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.050308\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.029262\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.017580\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.035994\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.050498\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.115240\n",
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 986/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 1974/10000 (20%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039, Accuracy: 2965/10000 (30%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 3948/10000 (39%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037, Accuracy: 4933/10000 (49%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048, Accuracy: 5917/10000 (59%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 6901/10000 (69%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0060, Accuracy: 7881/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052, Accuracy: 8862/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035, Accuracy: 9854/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,EPOCH+1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e4fa6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-168ec425bf87>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = model(examples_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780a77c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(examples_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
